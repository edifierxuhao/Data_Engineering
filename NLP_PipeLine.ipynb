{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How NLP Pipelines Work\n",
    "The 3 stages of an NLP pipeline are: Text Processing > Feature Extraction > Modeling.\n",
    "\n",
    "- **Text Processing**: Take raw input text, clean it, normalize it, and convert it into a form that is suitable for feature extraction.\n",
    "- **Feature Extraction**: Extract and produce feature representations that are appropriate for the type of NLP task you are trying to accomplish and the type of model you are planning to use.\n",
    "- **Modeling**: Design a statistical or machine learning model, fit its parameters to training data, use an optimization procedure, and then use it to make predictions about unseen data.\n",
    "\n",
    "This process isn't always linear and may require additional steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Text Processing\n",
    "The first chunk of this lesson will explore the steps involved in text processing, the first stage of the NLP pipeline.\n",
    "\n",
    "## Why Do We Need to Process Text?\n",
    "- Extracting plain text: Textual data can come from a wide variety of sources: the web, PDFs, word documents, speech recognition systems, book scans, etc. Your goal is to extract plain text that is free of any source specific markup or constructs that are not relevant to your task.\n",
    "- Reducing complexity: Some features of our language like capitalization, punctuation, and common words such as a, of, and the, often help provide structure, but don't add much meaning. Sometimes it's best to remove them if that helps reduce the complexity of the procedures you want to apply later.\n",
    "\n",
    "You'll prepare text data from different sources with the following text processing steps:\n",
    "\n",
    "1. Cleaning to remove irrelevant items, such as HTML tags\n",
    "2. Normalizing by converting to all lowercase and removing punctuation\n",
    "3. Splitting text into words or tokens\n",
    "4. Removing words that are too common, also known as stop words\n",
    "5. Identifying different parts of speech and named entities\n",
    "6. Converting words into their dictionary forms, using stemming and lemmatization\n",
    "\n",
    "After performing these steps, your text will capture the essence of what was being conveyed in a form that is easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "Let's walk through an example of cleaning text data from a popular source - the web. You'll be introduced to helpful tools in working with this data, including the requests library, regular expressions, and Beautiful Soup.\n",
    "\n",
    "## Documentation for Python Libraries:\n",
    "- [Requests](https://docs.python.org/3/library/urllib.request.html?highlight=request)\n",
    "- [Regular Expressions](https://docs.python.org/3/library/re.html)\n",
    "- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Quiz: Udacity's Course Catalog\n",
    "It's your turn! Udacity's [course catalog page](https://www.udacity.com/courses/all) has changed since the last video was filmed. One notable change is the introduction of  _schools_.\n",
    "\n",
    "In this activity, you're going to perform similar actions with BeautifulSoup to extract the following information from each course listing on the page:\n",
    "1. The course name - e.g. \"Data Analyst\"\n",
    "2. The school the course belongs to - e.g. \"School of Data Science\"\n",
    "\n",
    "**Note: All solution notebooks can be found by clicking on the Jupyter icon on the top left of this workspace.**\n",
    "\n",
    "### Step 1: Get text from Udacity's course catalog web page\n",
    "You can use the `requests` library to do this.\n",
    "\n",
    "Outputting all the javascript, CSS, and text may overload the space available to load this notebook, so we omit a print statement here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch web page\n",
    "r = requests.get('https://www.udacity.com/courses/all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use BeautifulSoup to remove HTML tags\n",
    "Use `\"lxml\"` rather than `\"html5lib\"`.\n",
    "\n",
    "Again, outputting all the results may overload the space available to load this notebook, so we omit a print statement here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text,'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Find all course summaries\n",
    "Use the BeautifulSoup's `find_all` method to select based on tag type and class name. Just ike in the video, you can right click on the item, and click \"Inspect\" to view its html on a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Courses: 236\n"
     ]
    }
   ],
   "source": [
    "# Find all course summaries\n",
    "summaries = soup.find_all('div',class_ = 'card-content')\n",
    "print('Number of Courses:', len(summaries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Inspect the first summary to find selectors for the course name and school\n",
    "Tip: `.prettify()` is a super helpful method BeautifulSoup provides to output html in a nicely indented form! Make sure to use `print()` to ensure whitespace is displayed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div _ngcontent-sc216=\"\" class=\"card-content\">\n",
      " <!-- -->\n",
      " <span _ngcontent-sc216=\"\" class=\"tag tag--new card ng-star-inserted\">\n",
      "  New\n",
      " </span>\n",
      " <!-- -->\n",
      " <div _ngcontent-sc216=\"\" class=\"category-wrapper\">\n",
      "  <span _ngcontent-sc216=\"\" class=\"mobile-icon\">\n",
      "  </span>\n",
      "  <!-- -->\n",
      "  <h4 _ngcontent-sc216=\"\" class=\"category ng-star-inserted\">\n",
      "   School of Business\n",
      "  </h4>\n",
      " </div>\n",
      " <h3 _ngcontent-sc216=\"\" class=\"card-heading\">\n",
      "  <a _ngcontent-sc216=\"\" class=\"capitalize\" href=\"/course/ai-for-business-leaders--nd054\">\n",
      "   AI for Business Leaders\n",
      "  </a>\n",
      " </h3>\n",
      " <div _ngcontent-sc216=\"\" class=\"right-sub\">\n",
      "  <!-- -->\n",
      "  <div _ngcontent-sc216=\"\" class=\"skills ng-star-inserted\">\n",
      "   <h4 _ngcontent-sc216=\"\">\n",
      "    Skills Covered\n",
      "   </h4>\n",
      "   <span _ngcontent-sc216=\"\" class=\"truncate-content\">\n",
      "    <!-- -->\n",
      "    <span _ngcontent-sc216=\"\" class=\"ng-star-inserted\">\n",
      "     Artificial Intelligence,\n",
      "    </span>\n",
      "    <span _ngcontent-sc216=\"\" class=\"ng-star-inserted\">\n",
      "     Machine Learning,\n",
      "    </span>\n",
      "    <span _ngcontent-sc216=\"\" class=\"ng-star-inserted\">\n",
      "     Business Strategy,\n",
      "    </span>\n",
      "    <span _ngcontent-sc216=\"\" class=\"ng-star-inserted\">\n",
      "     Data Labeling,\n",
      "    </span>\n",
      "    <span _ngcontent-sc216=\"\" class=\"ng-star-inserted\">\n",
      "     Data Modeling\n",
      "    </span>\n",
      "   </span>\n",
      "  </div>\n",
      "  <!-- -->\n",
      "  <div _ngcontent-sc216=\"\" class=\"hidden-md-up level\">\n",
      "   <span _ngcontent-sc216=\"\" class=\"course-level course-level-intermediate\" classname=\"course-level course-level-intermediate\">\n",
      "   </span>\n",
      "   <span _ngcontent-sc216=\"\" class=\"capitalize\">\n",
      "    intermediate\n",
      "   </span>\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# print the first summary in summaries\n",
    "print(summaries[0].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for selectors that contain the courses title and school name text you want to extract. Then, use the `select_one` method on the summary object to pull out the html with those selectors. Afterwards, don't forget to do some extra cleaning to isolate the names (get rid of unnecessary html), as you saw in the last video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI for Business Leaders'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract course title\n",
    "summaries[0].select_one('h3 a').get_text().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'School of Business'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract school\n",
    "summaries[0].select('h4')[0].get_text().strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Collect names and schools of ALL course listings\n",
    "Reuse your code from the previous step, but now in a loop to extract the name and school from every course summary in `summaries`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = []\n",
    "for summary in summaries:\n",
    "    title = summary.select_one('h3 a').get_text().strip()\n",
    "    school = summary.select('h4')[0].get_text().strip()\n",
    "    \n",
    "    # append name and school of each summary to courses list\n",
    "    courses.append((title,school))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236 course summaries found. Sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('AI for Business Leaders', 'School of Business'),\n",
       " ('Intro to Machine Learning with TensorFlow',\n",
       "  'School of Artificial Intelligence'),\n",
       " ('UX Designer', 'School of Business'),\n",
       " ('Data Streaming', 'School of Data Science'),\n",
       " ('Front End Web Developer', 'School of Programming'),\n",
       " ('Full Stack Web Developer', 'School of Programming'),\n",
       " ('Java Developer', 'School of Programming'),\n",
       " ('AI Product Manager', 'School of Artificial Intelligence'),\n",
       " ('Sensor Fusion Engineer', 'School of Autonomous Systems'),\n",
       " ('Data Visualization', 'School of Data Science'),\n",
       " ('Cloud Developer', 'School of Cloud Computing'),\n",
       " ('Cloud DevOps Engineer', 'School of Cloud Computing'),\n",
       " ('Intro to Machine Learning with PyTorch',\n",
       "  'School of Artificial Intelligence'),\n",
       " ('C++', 'School of Autonomous Systems'),\n",
       " ('Data Structures and Algorithms', 'School of Programming'),\n",
       " ('Programming for Data Science with R', 'School of Data Science'),\n",
       " ('Data Engineer', 'School of Data Science'),\n",
       " ('Marketing Analytics', 'School of Business'),\n",
       " ('Introduction to Programming', 'School of Programming'),\n",
       " ('Data Analyst', 'School of Data Science'),\n",
       " ('iOS Developer', 'School of Programming'),\n",
       " ('Predictive Analytics for Business', 'School of Business'),\n",
       " ('Machine Learning Engineer', 'School of Artificial Intelligence'),\n",
       " ('Self Driving Car Engineer', 'School of Autonomous Systems'),\n",
       " ('Digital Marketing', 'School of Business'),\n",
       " ('React', 'School of Programming'),\n",
       " ('Data Scientist', 'School of Data Science'),\n",
       " ('AI Programming with Python', 'School of Artificial Intelligence'),\n",
       " ('Business Analytics', 'School of Business'),\n",
       " ('Deep Learning', 'School of Artificial Intelligence'),\n",
       " ('Programming for Data Science with Python', 'School of Data Science'),\n",
       " ('Intro to Self-Driving Cars', 'School of Autonomous Systems'),\n",
       " ('Blockchain Developer', 'School of Programming'),\n",
       " ('Robotics Software Engineer', 'School of Autonomous Systems'),\n",
       " ('Flying Car and Autonomous Flight Engineer', 'School of Autonomous Systems'),\n",
       " ('Android Developer', 'School of Programming'),\n",
       " ('Android Basics', 'School of Programming'),\n",
       " ('Artificial Intelligence for Trading', 'School of Artificial Intelligence'),\n",
       " ('Computer Vision', 'School of Artificial Intelligence'),\n",
       " ('Natural Language Processing', 'School of Artificial Intelligence')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display results\n",
    "print(len(courses), \"course summaries found. Sample:\")\n",
    "courses[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
